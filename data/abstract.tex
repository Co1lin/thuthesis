% !TeX root = ../thuthesis-example.tex

% 中英文摘要和关键字

\begin{abstract}

深度学习编译器是将神经网络模型部署到特定硬件平台上并进行优化的核心工具，其正确性对提高神经网络实际应用的可靠性至关重要。
近年来，已有研究者利用软件工程领域中寻找程序漏洞的常用技术——模糊测试，通过生成大量包含单个或多个算子的测试用例，结合差分测试，寻找深度学习编译器中的实现错误。然而，这些已有工作所生成测例的多样性仍存在提升空间，未能触发编译器中尽可能多的优化逻辑，以实现充分测试。

面对上述问题，在方法上，本文提出符号化计算图生成这一已有算法的一种改进策略，通过引入具体化算子进行混合计算图生成，提高了模糊测试用例中计算图的多样性。实验表明，对于 PyTorch 与 TensorFlow 两种主流框架，该方法可以分别提高分支覆盖数 14.9\% 、 23.5\% ，研究过程中累计提交漏洞 62 个、 14 个，且在测例多样性与实际意义两方面均具有明显优势。
同时，本文提出了一套在具体算子数据集上进行分类的规则，为基于自动规则与约束推导进行测例生成的未来工作奠定了基础。

在工程上，本文基于前人已有的开源项目 NNSmith 进行拓展，不仅实现了上述方法中的具体算子收集与分类以及混合计算图生成，而且实现了模型的 Python 代码描述与图结构中间表示的相互转换，从而提高了测例的有效性，并为充分利用已有代码提供了实现基础。本文的核心功能已经在 GitHub 上被提交与整合至 NNSmith 仓库，为后续研究的跟进与实际场景中的应用提供了便利。

在经验上，本文呈现了深度学习编译器实现中的典型错误，并分析了触发它们的根因，直观体现了深度学习模糊测试框架的意义，与机器学习系统可靠性研究的重要性。
  
  % 论文的摘要是对论文研究内容和成果的高度概括。
  % 摘要应对论文所研究的问题及其研究目的进行描述，对研究方法和过程进行简单介绍，对研究成果和所得结论进行概括。
  % 摘要应具有独立性和自明性，其内容应包含与论文全文同等量的主要信息。
  % 使读者即使不阅读全文，通过摘要就能了解论文的总体内容和主要成果。

  % 论文摘要的书写应力求精确、简明。
  % 切忌写成对论文书写内容进行提要的形式，尤其要避免“第 1 章……；第 2 章……；……”这种或类似的陈述方式。

  % 关键词是为了文献标引工作、用以表示全文主要内容信息的单词或术语。
  % 关键词不超过 5 个，每个关键词中间用分号分隔。

  % 关键词用“英文逗号”分隔，输出时会自动处理为正确的分隔符
\thusetup{
  keywords = {深度学习编译器, 计算图, 测例生成, 模糊测试, 差分测试},
}
\end{abstract}

\begin{abstract*}
Deep learning compiler is a core tool to deploy neural network models to specific hardware platforms and optimize them, and its correctness is crucial to improve the reliability of neural network applications.
In recent years, some researchers have used the common technology of finding program bugs in the field of software engineering, fuzzing, to find implementation errors in deep learning compilers by generating a large number of test cases containing single or multiple operators and combining differential testing. However, the diversity of the generated test cases still has room for improvement, and the optimization logic in the compiler has not been triggered as much as possible to achieve sufficient testing.

Facing the problems above, in terms of method, we extend the existing graph generation algorithm, symbolic graph generation, by introducing concrete operators for hybrid graph generation, which improves the diversity of computation graphs in fuzzing test cases.
Experiments show that for the two commonly used frameworks, PyTorch and TensorFlow, our method can respectively improve the branch coverage by 14.9\% and 23.5\%, and submit 62 and 14 bugs or vulnerabilities in the research process, with advantages in both test case diversity and practical significance.
Meanwhile, we propose a set of rules for classification on the concrete operator dataset, which lays the foundation for future work on test case generation based on automatic rule and constraint inference.

In terms of engineering, we extend the existing open source project NNSmith. We not only implement the collection and classification of concrete operators as well as the hybrid computation graph generation, but also implement the mutual conversion between the Python code description of the model and the intermediate representation of the graph, which enhances the effectiveness of the test case and provides an implementation basis for making full use of existing code from other sources.
The core functions of this project have been merged into the NNSmith repository on GitHub, which provides convenience for follow-up research and application in real scenarios.

Empirically, we demonstrate typical bugs hidden behind deep learning compilers and analyze their root causes, intuitively presenting the significance of fuzzing deep learning frameworks and the importance of reliability research on modern machine learning systems. 

% Use comma as separator when inputting
\thusetup{
  keywords* = {Deep Learning Compiler, Computation Graph, Test Case Generation, Fuzzing, Differential Testing},
}
\end{abstract*}
